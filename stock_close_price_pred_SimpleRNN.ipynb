{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stylish-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# build a simple rnn with cleaned test data to predict close price\n",
    "# step1: import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, SimpleRNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passive-makeup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>rise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200221</td>\n",
       "      <td>10.70</td>\n",
       "      <td>0.006585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200224</td>\n",
       "      <td>10.56</td>\n",
       "      <td>-0.013084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200225</td>\n",
       "      <td>10.49</td>\n",
       "      <td>-0.006629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200226</td>\n",
       "      <td>10.60</td>\n",
       "      <td>0.010486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20200227</td>\n",
       "      <td>10.61</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>20210301</td>\n",
       "      <td>10.58</td>\n",
       "      <td>0.003795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>20210302</td>\n",
       "      <td>10.47</td>\n",
       "      <td>-0.010397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>20210303</td>\n",
       "      <td>10.92</td>\n",
       "      <td>0.042980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>20210304</td>\n",
       "      <td>10.88</td>\n",
       "      <td>-0.003663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>20210305</td>\n",
       "      <td>10.86</td>\n",
       "      <td>-0.001838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  close      rise\n",
       "1    20200221  10.70  0.006585\n",
       "2    20200224  10.56 -0.013084\n",
       "3    20200225  10.49 -0.006629\n",
       "4    20200226  10.60  0.010486\n",
       "5    20200227  10.61  0.000943\n",
       "..        ...    ...       ...\n",
       "249  20210301  10.58  0.003795\n",
       "250  20210302  10.47 -0.010397\n",
       "251  20210303  10.92  0.042980\n",
       "252  20210304  10.88 -0.003663\n",
       "253  20210305  10.86 -0.001838\n",
       "\n",
       "[253 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clean_data import clean_csv_data\n",
    "stock_code = '600000'\n",
    "df = clean_csv_data(stock_code + '.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "contained-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2: 制定训练集和测试集\n",
    "# 总数据集大小\n",
    "data_sz = df.shape[0]\n",
    "# 计算测试集大小, 约为原数据的%20. 向上取整\n",
    "test_set_sz = math.ceil(data_sz * 0.2)\n",
    "training_set_sz = data_sz - test_set_sz\n",
    "# 前(data_sz - test_set_sz)天的涨幅作为训练集, 后test_set_sz天的涨幅作为测试集\n",
    "training_set = df.iloc[0:training_set_sz, 1:2].values\n",
    "test_set = df.iloc[-test_set_sz:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hispanic-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化到(0,1)之间\n",
    "sc = MinMaxScaler(feature_range=(0, 1))\n",
    "# 求得训练集的最大值，最小值这些训练集固有的属性，并在训练集上进行归一化\n",
    "training_set_scaled = sc.fit_transform(training_set) \n",
    "test_set = sc.transform(test_set)  # 利用训练集的属性对测试集进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "described-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "sample_sz = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suitable-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用for循环，遍历整个训练集，提取训练集中连续sample_sz=15天的开盘价作为输入特征x_train，\n",
    "# 第16天的数据作为标签，for循环共构建training_set_sz-15组数据。\n",
    "for i in range(sample_sz, len(training_set_scaled)):\n",
    "    x_train.append(training_set_scaled[i - sample_sz:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "# 对训练集进行打乱\n",
    "np.random.seed(56)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.seed(56)\n",
    "np.random.shuffle(y_train)\n",
    "tf.random.set_seed(56)\n",
    "# 将训练集由list格式变为array格式\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "front-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN输入：[送入样本数， 循环核时间展开步数， 每个时间步输入特征个数]\n",
    "# 此处整个数据集送入，送入样本数为x_train.shape[0]组数据；输入sample_sz个开盘价，预测出第sample_sz+1天的开盘价，\n",
    "# 循环核时间展开步数为sample_sz; 每个时间步送入的特征是某一天的开盘价，只有1个数据，故每个时间步输入特征个数为1\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], sample_sz, 1))\n",
    "# 测试集\n",
    "for i in range(sample_sz, test_set_sz):\n",
    "    x_test.append(test_set[i - sample_sz:i, 0])\n",
    "    y_test.append(test_set[i, 0])\n",
    "# 测试集变array并reshape为符合RNN输入要求\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], sample_sz, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brazilian-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3: 逐层搭建网络结构\n",
    "model = tf.keras.Sequential([\n",
    "    SimpleRNN(80, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(100),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "direct-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4: 在 model.compile()中配置训练方法，选择训练时使用的优化器、损失函数和最终评价指标。\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='mean_squared_error')  # 损失函数用均方误差\n",
    "# 该应用只观测loss数值，不观测准确率，所以删去metrics选项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "front-hungarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------load the model-----------------\n",
      "Train on 192 samples, validate on 41 samples\n",
      "Epoch 1/50\n",
      "192/192 [==============================] - 2s 8ms/sample - loss: 0.0208 - val_loss: 0.0119\n",
      "Epoch 2/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0133 - val_loss: 0.0048\n",
      "Epoch 3/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 4/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 5/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0105 - val_loss: 0.0051\n",
      "Epoch 6/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0107 - val_loss: 0.0064\n",
      "Epoch 7/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 8/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 9/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0086 - val_loss: 0.0062\n",
      "Epoch 10/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0092 - val_loss: 0.0077\n",
      "Epoch 11/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0086 - val_loss: 0.0076\n",
      "Epoch 12/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 13/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 14/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 15/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 16/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 17/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 18/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 19/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0055 - val_loss: 0.0070\n",
      "Epoch 20/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 21/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 22/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 23/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 24/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 25/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 26/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 27/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 28/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 29/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0053 - val_loss: 0.0082\n",
      "Epoch 30/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 31/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 32/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 33/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 34/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 35/50\n",
      "192/192 [==============================] - 0s 1ms/sample - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 36/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0050 - val_loss: 0.0107\n",
      "Epoch 37/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 38/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 39/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0050 - val_loss: 0.0062\n",
      "Epoch 40/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 41/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 42/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0046 - val_loss: 0.0067\n",
      "Epoch 43/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 44/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 45/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0055 - val_loss: 0.0090\n",
      "Epoch 46/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0049 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0048 - val_loss: 0.0082\n",
      "Epoch 48/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 49/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 50/50\n",
      "192/192 [==============================] - 0s 2ms/sample - loss: 0.0044 - val_loss: 0.0063\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       multiple                  6560      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     multiple                  18100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  101       \n",
      "=================================================================\n",
      "Total params: 24,761\n",
      "Trainable params: 24,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 存取模型(断点续训)\n",
    "# 读取模型\n",
    "checkpoint_save_path = \"./checkpoint/stock_close_price_pred_SimpleRNN.ckpt\"\n",
    "\n",
    "if os.path.exists(checkpoint_save_path + '.index'):\n",
    "    print('-------------load the model-----------------')\n",
    "    model.load_weights(checkpoint_save_path)\n",
    "\n",
    "# 保存模型\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor='val_loss')\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=4, epochs=50, validation_data=(x_test, y_test), validation_freq=1,\n",
    "                    callbacks=[cp_callback])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "infectious-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数提取存入文本\n",
    "file = open('./weights/stock_close_price_pred_SimpleRNN_weights.txt', 'w')  \n",
    "for v in model.trainable_variables:\n",
    "    file.write(str(v.name) + '\\n')\n",
    "    file.write(str(v.shape) + '\\n')\n",
    "    file.write(str(v.numpy()) + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ceramic-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 可视化\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('RNN_Close_Price_Loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "steady-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测\n",
    "# 测试集输入模型进行预测\n",
    "predicted_stock_cl_price = model.predict(x_test)\n",
    "# 对预测数据还原---从（0，1）反归一化到原始范围\n",
    "predicted_stock_cl_price = sc.inverse_transform(predicted_stock_cl_price)\n",
    "# 对真实数据还原---从（0，1）反归一化到原始范围\n",
    "real_stock_cl_price = sc.inverse_transform(test_set[sample_sz:])\n",
    "# 画出真实数据和预测数据的对比曲线\n",
    "plt.figure(2)\n",
    "plt.plot(real_stock_cl_price, color='red', label='real close price')\n",
    "plt.plot(predicted_stock_cl_price, color='blue', label='predicted close price')\n",
    "plt.title('stock code '+stock_code + ' close price prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock close price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('RNN_Close_Price_Pridiction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-double",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TF2.1]",
   "language": "python",
   "name": "conda-env-TF2.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
